From 17f2187628253d4ca87cb51309e535038de3ce0e Mon Sep 17 00:00:00 2001
From: liberodark <liberodark@gmail.com>
Date: Wed, 26 Nov 2025 11:23:23 +0100
Subject: [PATCH 03/18] mm/slub: move kmem_cache_order_objects to the top of

---
 mm/slab.h | 31 ++++++++++++++++++++++---------
 mm/slub.c | 12 ------------
 2 files changed, 22 insertions(+), 21 deletions(-)

diff --git a/mm/slab.h b/mm/slab.h
index b4a1c0c69..bf4e92f1c 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -48,6 +48,15 @@ typedef union {
 	freelist_full_t full;
 } freelist_aba_t;
 
+/*
+ * Word size structure that can be atomically updated or read and that
+ * contains both the order and the number of objects that a slab of the
+ * given order would contain.
+ */
+struct kmem_cache_order_objects {
+	unsigned int x;
+};
+
 /* Reuses the bits in struct page */
 struct slab {
 	unsigned long __page_flags;
@@ -225,6 +234,19 @@ static inline struct slab *virt_to_slab(const void *addr)
 	return folio_slab(folio);
 }
 
+#define OO_SHIFT	16
+#define OO_MASK		((1 << OO_SHIFT) - 1)
+
+static inline unsigned int oo_order(struct kmem_cache_order_objects x)
+{
+	return x.x >> OO_SHIFT;
+}
+
+static inline unsigned int oo_objects(struct kmem_cache_order_objects x)
+{
+	return x.x & OO_MASK;
+}
+
 static inline int slab_order(const struct slab *slab)
 {
 	return folio_order(slab_folio(slab));
@@ -252,15 +274,6 @@ static inline size_t slab_size(const struct slab *slab)
 #define slub_percpu_partial_read_once(c)	NULL
 #endif // CONFIG_SLUB_CPU_PARTIAL
 
-/*
- * Word size structure that can be atomically updated or read and that
- * contains both the order and the number of objects that a slab of the
- * given order would contain.
- */
-struct kmem_cache_order_objects {
-	unsigned int x;
-};
-
 /*
  * Slab cache management.
  */
diff --git a/mm/slub.c b/mm/slub.c
index 4da93afb2..98e12ca31 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -300,8 +300,6 @@ static inline bool kmem_cache_has_cpu_partial(struct kmem_cache *s)
  */
 #define DEBUG_METADATA_FLAGS (SLAB_RED_ZONE | SLAB_POISON | SLAB_STORE_USER)
 
-#define OO_SHIFT	16
-#define OO_MASK		((1 << OO_SHIFT) - 1)
 #define MAX_OBJS_PER_PAGE	32767 /* since slab.objects is u15 */
 
 /* Internal SLUB flags */
@@ -592,16 +590,6 @@ static inline struct kmem_cache_order_objects oo_make(unsigned int order,
 	return x;
 }
 
-static inline unsigned int oo_order(struct kmem_cache_order_objects x)
-{
-	return x.x >> OO_SHIFT;
-}
-
-static inline unsigned int oo_objects(struct kmem_cache_order_objects x)
-{
-	return x.x & OO_MASK;
-}
-
 #ifdef CONFIG_SLUB_CPU_PARTIAL
 static void slub_set_cpu_partial(struct kmem_cache *s, unsigned int nr_objects)
 {
-- 
2.50.1

